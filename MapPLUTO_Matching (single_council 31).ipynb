#!/usr/bin/env python
# coding: utf-8

# In[192]:


import pandas as pd
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
import json
import geopandas as gpd
import warnings
warnings.filterwarnings("ignore")
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from datetime import datetime
from shapely.geometry import Point


# ### Adding Block Group to all pluto

# In[193]:


df=pd.read_csv("C:/Users/Shetty/OneDrive/Desktop/NYU/Independent Study/NREL/MapPLUTO/pluto_22v3.csv")
df.head()


# In[194]:


df['geometry'] = df.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)
df.head()


# In[195]:


gdf = gpd.GeoDataFrame(df, geometry='geometry')


# In[196]:


bg = gpd.read_file("C:/Users/Shetty/OneDrive/Desktop/NYU/Independent Study/NREL/Location/Block Group/tl_2017_36_bg.shp")
bg.head()


# In[197]:


bg = bg[bg["COUNTYFP"].isin(['005','047','061','081','085'])]
bg.head()


# In[198]:


#pluto with puma and bg
result = gpd.sjoin(gdf, bg, op='within')
result.head()


# In[199]:


cols_01=['bbl','unit.sqft','numfloors','unitstotal','yearbuilt',"geometry",'GEOID']
result["unit.sqft"]=result["bldgarea"]/result["unitstotal"]
result=result[cols_01]
result.head()


# In[200]:


result.rename(columns={'geometry': 'Bldg_loc', 'GEOID': 'Block_Group'}, inplace=True)


# In[201]:


gdf=gpd.GeoDataFrame(pd.merge(bg,result,left_on="GEOID", right_on = "Block_Group", how="inner"))
gdf.head()


# In[188]:


#gdf.to_csv("pluto+bg.csv")


# In[203]:


#gdf['geometry'] = gdf['geometry'].apply(lambda x: x.wkt)
#gdf.to_file("pluto_bg.shp", driver="ESRI Shapefile")


# ### Council District 31

# In[204]:


df = pd.read_csv("C:/Users/Shetty/OneDrive/Desktop/NYU/Independent Study/NREL/Location/pluto+Puma+BG_31.csv")
df.head()


# In[205]:


df = df[(df["council"]==31) & (df["landuse"]==1)]
df.head()


# In[206]:


df["unit.sqft"]=df["bldgarea"]/df["unitstotal"]
df["unit.sqft"].head()


# In[207]:


cols_01=['bbl','unit.sqft','numfloors','unitstotal','yearbuilt','GISJOIN','latitude','longitude','Block_Group']

cols_02=['bldg_id','in.sqft','in.geometry_stories','in.geometry_building_number_units_mf','in.vintage_acs',
         'in.geometry_building_type_recs','in.puma','out.natural_gas.total.energy_consumption_intensity',
         'out.site_energy.total.energy_consumption_intensity','in.geometry_garage','in.heating_fuel']


# In[208]:


df_match=df[cols_01]
#df_match.to_csv("pluto_84_match.csv")
df_match.head()


# In[209]:


df_match["Block_Group"].value_counts().head()


# In[32]:


#df_match.to_csv("Pluto_BG.csv")


# In[33]:


#bg_shp=gpd.read_file("C:/Users/Shetty/OneDrive/Desktop/NYU/Independent Study/NREL/Location/Block Group/tl_2017_36_bg.shp")
#bg_shp.head()


# In[34]:


#merged = pd.merge(df, bg_shp, left_on='Block_Group', right_on='GEOID')
#merged.head()


# #### Removing end profiles with garage from ResStock

# In[210]:


res = pd.read_csv("C:/Users/Shetty/OneDrive/Desktop/NYU/Independent Study/NREL/Metadata/Metadata_NYC_170123.csv")
res=res[res["in.geometry_garage"]=='None']
res_match=res[cols_02]
res_match.head()


# In[211]:


res_match["in.geometry_building_type_recs"].value_counts()


# In[212]:


res_match = res_match[(res_match["in.geometry_building_type_recs"] == "Single-Family Detached") | 
                      (res_match["in.geometry_building_type_recs"] == "Single-Family Attached") |
                     (res_match["in.geometry_building_type_recs"] == "Multi-Family with 2 - 4 Units")]


# In[38]:


res_match["in.geometry_building_number_units_mf"].value_counts()


# In[213]:


res_match = res_match[(res_match["in.geometry_building_number_units_mf"]=='None') | (res_match["in.geometry_building_number_units_mf"]=='2')]


# In[214]:


res_match.shape


# In[215]:


res_match.head()


# In[216]:


df_match.head()


# In[217]:


df_match["unitstotal"].value_counts()


# #### 1) unit sq.ft bins

# In[218]:


sns.boxplot(res_match['in.sqft'])
plt.show()


# In[219]:


df_match.shape


# In[220]:


#remove inf and zero
df_match=df_match[(df_match['unit.sqft']!=np.inf) & (df_match['unit.sqft']!=0)]
df_match.shape


# In[221]:


sns.boxplot(df_match['unit.sqft'])
plt.show()


# In[222]:


res_match['in.sqft_bins'] = pd.qcut(res_match['in.sqft'], 12, duplicates='drop')
res_match['in.sqft_bins'].value_counts()


# In[223]:


res_match.shape


# In[224]:


df_match=df_match[df_match['unit.sqft'] <= 14000]


# In[225]:


res_match.head()


# In[226]:


bin_edges = [0,617.0,853.0,1138.0,1202.0,1623.0,1675.0,1690.0,2176.0,2663.0,14000]
df_match['in.sqft_bins'] = pd.cut(df_match['unit.sqft'], bins=bin_edges)
res_match['in.sqft_bins']= pd.cut(res_match['in.sqft'], bins=bin_edges)


# In[227]:


res_match.head()


# In[228]:


df_match.head()


# In[229]:


df_match['in.sqft_bins'].value_counts()


# #### 2) Age of building

# In[230]:


bin_edges = [0,1940,1960,1980,2000,2010,2023]
df_match['year_bins'] = pd.cut(df_match['yearbuilt'], bins=bin_edges, labels=['<1940','1940-59','1960-79','1980-99','2000-09','2010s'])
df_match.head()


# In[231]:


res_match = res_match.rename(columns={'in.vintage_acs': 'year_bins'})


# In[232]:


res_match.head()


# #### 3) Number of Units

# In[233]:


res_match.head()


# In[234]:


res_match["in.geometry_building_number_units_mf"].value_counts()


# In[235]:


res_match["in.geometry_building_number_units_mf"]=res_match["in.geometry_building_number_units_mf"].replace("None","1")


# In[236]:


res_match["in.geometry_building_number_units_mf"]=res_match["in.geometry_building_number_units_mf"].astype(float)


# In[237]:


df_match["unitstotal"].value_counts()


# In[238]:


res_match["in.geometry_building_number_units_mf"].value_counts()


# #### 4) Floors

# In[239]:


res_match['floors_bins'] = pd.qcut(res_match['in.geometry_stories'], 10, duplicates='drop')
res_match['floors_bins'].value_counts()


# In[240]:


df_match['floors_bins'] = pd.qcut(df_match['numfloors'], 3, duplicates='drop')
df_match['floors_bins'].value_counts()


# In[241]:


res_match['in.geometry_stories'].value_counts()


# In[242]:


df_match.head()


# In[243]:


df_match['numfloors'].max()


# In[244]:


bin_edges = [0,1.99,5]
df_match['floors_bins'] = pd.cut(df_match['numfloors'], bins=bin_edges, labels=['<2','>2'])
res_match['floors_bins'] = pd.cut(res_match['in.geometry_stories'], bins=bin_edges, labels=['<2','>2'])
df_match.head()


# In[245]:


res_match.head()


# In[246]:


res_match = res_match.rename(columns={'in.puma': 'Puma', 'in.geometry_building_number_units_mf': 'no_units'})
df_match = df_match.rename(columns={'GISJOIN': 'Puma', 'unitstotal': 'no_units'})


# In[247]:


df_match.shape


# In[248]:


#df_match.reset_index(inplace=True)
#df_match.head()


# In[249]:


#df_match['index'].nunique()


# ### Merging Dataframes

# In[250]:


res_plu = pd.merge(df_match, res_match, on=['Puma', 'year_bins', 'in.sqft_bins', 'no_units', 'floors_bins'],how='inner')
res_plu.head()


# ### How many load profiles were matched to each building?

# In[251]:


grouped = res_plu.groupby('bbl')['bldg_id'].apply(list)
grouped = grouped.reset_index()
grouped['num_bldg_ids'] = grouped['bldg_id'].apply(lambda x: len(x))
grouped.head()


# In[252]:


grouped['num_bldg_ids'].max()


# In[253]:


grouped.shape


# In[254]:


#grouped.to_csv("bbl_bldg_num.csv")


# In[255]:


grouped["num_bldg_ids"].value_counts()


# ## Pruning

# ### Heating Fuel

# In[267]:


hf_bg=pd.read_csv("C:/Users/Shetty/OneDrive/Desktop/NYU/Independent Study/NREL/Validate/Queens_BG_Heating Fuel/Heating fuel_BG_without error.csv")
hf_bg.head()


# In[268]:


hf_bg["geoid"]=hf_bg["geoid"].str[7:]


# In[269]:


hf_bg.shape


# In[270]:


res_plu['Block_Group'] = res_plu['Block_Group'].astype(str)


# In[271]:


hf_bg = hf_bg[hf_bg['geoid'].isin(res_plu['Block_Group'].tolist())]


# In[272]:


hf_bg.shape


# In[273]:


res_plu.head()


# In[274]:


res_plu["in.heating_fuel"].value_counts()


# In[275]:


#choosing rows will more matches than 1 to optimize
#df = res_plu.groupby('bbl')['bldg_id'].apply(list)
#df = df.reset_index()
#df['num_bldg_ids'] = df['bldg_id'].apply(lambda x: len(x))
#df = df[df["num_bldg_ids"]>1]
#df.head()


# In[276]:


#filtering out rows with one match
#res_01 = res_plu[res_plu["bbl"].isin(df["bbl"].to_list())]


# In[277]:


merged_df = pd.merge(res_plu, hf_bg, left_on='Block_Group', right_on='geoid', how='inner')

# Remove rows where heating fuel is 'electricity' and electricity is zero
merged_df = merged_df[~((merged_df['in.heating_fuel'] == 'Electricity') & (merged_df['Electricity'] == 0))]

# Keep only the columns from res_plu in the final dataframe
final_df = merged_df[res_plu.columns]


# In[278]:


grouped = final_df.groupby('bbl')['bldg_id'].apply(list)
grouped = grouped.reset_index()
grouped['num_bldg_ids'] = grouped['bldg_id'].apply(lambda x: len(x))

print(grouped['num_bldg_ids'].max())
print(grouped.shape)

grouped["num_bldg_ids"].value_counts()


# In[279]:


final_df.head()


# In[ ]:
